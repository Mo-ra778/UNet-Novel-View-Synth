"""
ğŸ® Phase 4 U-Net Web Demo
ÙˆØ§Ø¬Ù‡Ø© ØªÙØ§Ø¹Ù„ÙŠØ© Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
"""

import torch
import numpy as np
import gradio as gr
from PIL import Image
import os

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„ÙˆØ­Ø¯Ø§Øª Ø§Ù„Ù…Ø­Ù„ÙŠØ©
from model_unet import get_unet_model
from dataloader_phase4 import FixedShapeGenerator, render_shape, generate_stratified_random_views

# ============== Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ==============
MODEL_PATH = 'results_phase4_optimized/best_model.pth'
DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'
# ======================================

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
print("ğŸ“¦ Loading model...")
model = get_unet_model().to(DEVICE)
model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE, weights_only=True))
model.eval()
print(f"âœ… Model loaded on {DEVICE}")

# Ù…ÙˆÙ„Ø¯ Ø§Ù„Ø£Ø´ÙƒØ§Ù„
generator = FixedShapeGenerator()


def generate_random_shape(shape_id):
    """ØªÙˆÙ„ÙŠØ¯ Ø´ÙƒÙ„ Ø¹Ø´ÙˆØ§Ø¦ÙŠ"""
    shape_data = generator.generate_shape_by_id(shape_id)
    shape_color = generator.get_shape_color(shape_id)
    
    # Ø±Ø³Ù… Ù…Ù† Ø²Ø§ÙˆÙŠØ© Ø¹Ø´ÙˆØ§Ø¦ÙŠØ©
    views = generate_stratified_random_views(60, seed=shape_id)
    view = views[0]
    
    img_tensor = render_shape(shape_data, view[0], view[1], shape_color)
    img_np = img_tensor.permute(1, 2, 0).numpy()
    img_np = (img_np * 255).astype(np.uint8)
    
    return Image.fromarray(img_np), view[0], view[1]


def predict_view(source_image, target_elevation, target_azimuth):
    """Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„ØµÙˆØ±Ø© Ù…Ù† Ø§Ù„Ø²Ø§ÙˆÙŠØ© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©"""
    if source_image is None:
        return None, "âš ï¸ Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø±ÙØ¹ ØµÙˆØ±Ø© Ø£Ùˆ ØªÙˆÙ„ÙŠØ¯ Ø´ÙƒÙ„ Ø¹Ø´ÙˆØ§Ø¦ÙŠ"
    
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ù„Ù€ tensor
    img_np = np.array(source_image).astype(np.float32) / 255.0
    
    # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„ØµÙˆØ±Ø© RGB
    if len(img_np.shape) == 2:
        img_np = np.stack([img_np] * 3, axis=-1)
    elif img_np.shape[-1] == 4:
        img_np = img_np[:, :, :3]
    
    # ØªØºÙŠÙŠØ± Ø§Ù„Ø­Ø¬Ù… Ø¥Ù„Ù‰ 128x128
    from PIL import Image as PILImage
    img_pil = PILImage.fromarray((img_np * 255).astype(np.uint8))
    img_pil = img_pil.resize((128, 128), PILImage.LANCZOS)
    img_np = np.array(img_pil).astype(np.float32) / 255.0
    
    # ØªØ­ÙˆÙŠÙ„ Ù„Ù€ tensor
    img_tensor = torch.from_numpy(img_np).permute(2, 0, 1).unsqueeze(0).to(DEVICE)
    
    # ØªØ­Ø¶ÙŠØ± ÙƒØ§Ù…ÙŠØ±Ø§ Ø§Ù„Ù‡Ø¯Ù
    target_cam = torch.tensor([
        target_elevation / 90.0,
        target_azimuth / 180.0 - 1.0,
        1.0
    ], dtype=torch.float32).unsqueeze(0).to(DEVICE)
    
    # Ø§Ù„ØªÙ†Ø¨Ø¤
    with torch.no_grad():
        pred = model(img_tensor, target_cam)
    
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ù„ØµÙˆØ±Ø©
    pred_np = pred[0].cpu().permute(1, 2, 0).numpy()
    pred_np = np.clip(pred_np, 0, 1)
    pred_np = (pred_np * 255).astype(np.uint8)
    
    info = f"âœ… ØªÙ… Ø§Ù„ØªÙˆÙ„ÙŠØ¯!\nğŸ“ Elevation: {target_elevation:.1f}Â°\nğŸ”„ Azimuth: {target_azimuth:.1f}Â°"
    
    return Image.fromarray(pred_np), info


def generate_new_shape():
    """ØªÙˆÙ„ÙŠØ¯ Ø´ÙƒÙ„ Ø¹Ø´ÙˆØ§Ø¦ÙŠ Ø¬Ø¯ÙŠØ¯"""
    shape_id = np.random.randint(0, 15000)
    img, elev, azim = generate_random_shape(shape_id)
    info = f"ğŸ² Shape ID: {shape_id}\nğŸ“ Elevation: {elev:.1f}Â°\nğŸ”„ Azimuth: {azim:.1f}Â°"
    return img, info


def demo_360_rotation(source_image):
    """ØªÙˆÙ„ÙŠØ¯ Ø¯ÙˆØ±Ø§Ù† 360 Ø¯Ø±Ø¬Ø©"""
    if source_image is None:
        return None, "âš ï¸ Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø±ÙØ¹ ØµÙˆØ±Ø© Ø£ÙˆÙ„Ø§Ù‹"
    
    images = []
    for azim in range(0, 360, 30):
        pred_img, _ = predict_view(source_image, 30, azim)
        if pred_img:
            images.append(pred_img)
    
    # Ø¥Ù†Ø´Ø§Ø¡ ØµÙˆØ±Ø© Ù…Ø¬Ù…Ø¹Ø©
    if images:
        width = 128 * 4
        height = 128 * 3
        combined = Image.new('RGB', (width, height), 'white')
        
        for i, img in enumerate(images):
            x = (i % 4) * 128
            y = (i // 4) * 128
            combined.paste(img.resize((128, 128)), (x, y))
        
        return combined, f"âœ… ØªÙ… ØªÙˆÙ„ÙŠØ¯ 12 Ø²Ø§ÙˆÙŠØ© (ÙƒÙ„ 30Â°)"
    
    return None, "âŒ ÙØ´Ù„ Ø§Ù„ØªÙˆÙ„ÙŠØ¯"


# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©
with gr.Blocks(title="Phase 4 U-Net Demo") as demo:
    gr.Markdown("""
    # ğŸ® Phase 4 U-Net - Novel View Synthesis Demo
    ### ØªÙˆÙ„ÙŠØ¯ Ù…Ù†Ø§Ø¸Ø± Ø¬Ø¯ÙŠØ¯Ø© Ù„Ù„Ø£Ø´ÙƒØ§Ù„ Ø«Ù„Ø§Ø«ÙŠØ© Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯
    
    **Ø§Ù„Ù†ØªØ§Ø¦Ø¬:** PSNR = 35.59 dB | Similarity = 99.62%
    """)
    
    with gr.Row():
        with gr.Column():
            gr.Markdown("### ğŸ“¤ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…ØµØ¯Ø±")
            source_img = gr.Image(type="pil", label="ØµÙˆØ±Ø© Ø§Ù„Ù…ØµØ¯Ø±")
            
            with gr.Row():
                generate_btn = gr.Button("ğŸ² ØªÙˆÙ„ÙŠØ¯ Ø´ÙƒÙ„ Ø¹Ø´ÙˆØ§Ø¦ÙŠ", variant="secondary")
            
            source_info = gr.Textbox(label="Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ØµØ¯Ø±", lines=3)
            
        with gr.Column():
            gr.Markdown("### ğŸ¯ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø²Ø§ÙˆÙŠØ© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©")
            
            elevation = gr.Slider(0, 90, value=45, step=1, label="ğŸ“ Elevation (Ø¯Ø±Ø¬Ø©)")
            azimuth = gr.Slider(0, 360, value=180, step=1, label="ğŸ”„ Azimuth (Ø¯Ø±Ø¬Ø©)")
            
            predict_btn = gr.Button("ğŸš€ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ù†Ø¸Ø± Ø§Ù„Ø¬Ø¯ÙŠØ¯", variant="primary")
            
        with gr.Column():
            gr.Markdown("### ğŸ–¼ï¸ Ø§Ù„Ù†ØªÙŠØ¬Ø©")
            output_img = gr.Image(type="pil", label="Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…ÙˆÙ„Ø¯Ø©")
            output_info = gr.Textbox(label="Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªÙˆÙ„ÙŠØ¯", lines=3)
    
    gr.Markdown("---")
    
    with gr.Row():
        with gr.Column():
            rotation_btn = gr.Button("ğŸ”„ ØªÙˆÙ„ÙŠØ¯ Ø¯ÙˆØ±Ø§Ù† 360Â°", variant="secondary")
        with gr.Column():
            rotation_output = gr.Image(type="pil", label="Ø¯ÙˆØ±Ø§Ù† 360Â°")
            rotation_info = gr.Textbox(label="Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¯ÙˆØ±Ø§Ù†")
    
    # Ø§Ù„Ø£Ø­Ø¯Ø§Ø«
    generate_btn.click(
        fn=generate_new_shape,
        outputs=[source_img, source_info]
    )
    
    predict_btn.click(
        fn=predict_view,
        inputs=[source_img, elevation, azimuth],
        outputs=[output_img, output_info]
    )
    
    rotation_btn.click(
        fn=demo_360_rotation,
        inputs=[source_img],
        outputs=[rotation_output, rotation_info]
    )


if __name__ == "__main__":
    print("\n" + "=" * 50)
    print("ğŸŒ Starting Web Demo...")
    print("ğŸ“ Open: http://localhost:7860")
    print("=" * 50 + "\n")
    
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        show_error=True
    )
